{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting water level for the next 2 weeks to a month and writing the predictions out",
   "id": "311a8987d6435927"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-11T17:41:48.838279Z",
     "start_time": "2026-01-11T17:41:48.828873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import os\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--latitude\", type=float, default=59.3284)\n",
    "parser.add_argument(\"--longitude\", type=float, default=18.0664)\n",
    "parser.add_argument(\"--sensor-id\", type=int, default=20389)\n",
    "parser.add_argument(\"--sensor-name\", type=str, default=\"malaren_w\")\n",
    "parser.add_argument(\"--water-level-fg-version\", type=int, default=4)\n",
    "parser.add_argument(\"--weather-fg-version\", type=int, default=4)\n",
    "parser.add_argument(\"--fv-version\", type=int, default=2)\n",
    "parser.add_argument(\"--model-version\", type=int, default=1)\n",
    "parser.add_argument(\"--sensor-url\", type=str, default=\"invalid\")\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "latitude = args.latitude\n",
    "longitude = args.longitude\n",
    "sensor_id = args.sensor_id\n",
    "sensor_name = args.sensor_name\n",
    "water_level_fg_version = args.water_level_fg_version\n",
    "weather_fg_version = args.weather_fg_version\n",
    "fv_version = args.fv_version\n",
    "model_version = args.model_version"
   ],
   "id": "c8611faad07ae34",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Login to hopsworks",
   "id": "63a946a3f28a519e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:41:50.819367Z",
     "start_time": "2026-01-11T17:41:48.887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_key = os.environ.get(\"HOPSWORKS_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"HOPSWORKS_API_KEY is not set\")\n",
    "\n",
    "project = hopsworks.login(\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    port=443,\n",
    "    project=\"ml_project\",\n",
    "    api_key_value=api_key,\n",
    ")\n",
    "fs = project.get_feature_store()"
   ],
   "id": "78b1b274717adc4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 18:41:48,888 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-11 18:41:48,891 INFO: Connection closed.\n",
      "2026-01-11 18:41:48,893 INFO: Initializing external client\n",
      "2026-01-11 18:41:48,894 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-11 18:41:50,231 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/2184\n"
     ]
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract secrets from the feature store",
   "id": "b6dd75011e114b37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Download the model from Model Registry",
   "id": "381e3cdb24e0384d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:42:05.548085Z",
     "start_time": "2026-01-11T17:41:50.832146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import get_model_name\n",
    "\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "model_name = get_model_name(sensor_name, sensor_id)\n",
    "\n",
    "retrieved_model = mr.get_model(\n",
    "    name=model_name,\n",
    "    version=model_version\n",
    ")\n",
    "\n",
    "#Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ],
   "id": "1f5fc7b409efc042",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1333020 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55869d90c53047aeb0de939e18db09d2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1397527 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38de61ab01aa4fc686a77aba837e9bc6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1428145 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3252aba5e30c4fbd95cd26bd37d02f8f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/607210 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a1a7d577e2d414e8c0bf520b40a0b01"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1387617 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72aaadcaf6f94c00980fd4075cb9d2aa"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 5 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1403232 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fd7706a1f8d490badf060488682c4a7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 6 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1414005 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1186d4b006374f94af444e8fa4f6016f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 7 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1384138 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "675639909bcf47e2b43ac92fccbdfcfe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 8 files)... \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading: 0.000%|          | 0/1383353 elapsed<00:00 remaining<?"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41b9db8e993243e2bfae218be9683ba1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 9 files)... DONE\r"
     ]
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:42:05.616956Z",
     "start_time": "2026-01-11T17:42:05.557908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retrieved_xgboost_model = XGBRegressor()\n",
    "retrieved_xgboost_model.load_model(saved_model_dir + f\"/{model_name}.json\")\n",
    "retrieved_xgboost_model"
   ],
   "id": "63eea4a1bd97e61f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score='2.9236506E4', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float', 'float',\n",
       "                            'float', 'float', 'float', 'float', 'float',\n",
       "                            'float', 'float', 'float', 'float', 'floa...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ],
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;2.9236506E4&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;floa...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;2.9236506E4&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;,\n",
       "                            &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;floa...\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get the water level and weather forecast feature view",
   "id": "cf11247c10002b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:42:11.739623Z",
     "start_time": "2026-01-11T17:42:05.623757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import get_water_level_features, get_weather_features\n",
    "\n",
    "water_level_features = get_water_level_features()\n",
    "weather_features = get_weather_features()\n",
    "\n",
    "water_level_fg = fs.get_feature_group(\n",
    "    name=f\"water_level_lagged_{sensor_name}_{sensor_id}\",\n",
    "    version=water_level_fg_version,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name=f\"weather_features_{sensor_name}_{sensor_id}\",\n",
    "    version=weather_fg_version,\n",
    ")\n",
    "\n",
    "@hopsworks.udf(\n",
    "    return_type=[int] * 12,   # month_1 ... month_12\n",
    "    mode=\"pandas\"\n",
    ")\n",
    "def add_month_one_hot(date: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One-hot encode month from event-time column.\n",
    "    \"\"\"\n",
    "    # Extract month (1–12)\n",
    "    month = pd.to_datetime(date).dt.month\n",
    "\n",
    "    # One-hot encode\n",
    "    dummies = pd.get_dummies(month, prefix=\"month\")\n",
    "\n",
    "    # Ensure ALL 12 months exist (critical!)\n",
    "    for m in range(1, 13):\n",
    "        col = f\"month_{m}\"\n",
    "        if col not in dummies:\n",
    "            dummies[col] = 0\n",
    "\n",
    "    # Stable column order\n",
    "    dummies = dummies[[f\"month_{m}\" for m in range(1, 13)]]\n",
    "\n",
    "    return dummies.astype(\"int32\")\n",
    "\n",
    "query = (\n",
    "    water_level_fg\n",
    "    .select([\"date\"] + water_level_features)\n",
    "    .join(\n",
    "        weather_fg.select(weather_features),\n",
    "        on=[\"sensor_id\", \"date\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "fv = fs.get_or_create_feature_view(\n",
    "    name=f\"water_level_training_view_{sensor_name}_{sensor_id}\",\n",
    "    version=fv_version,\n",
    "    query=query,\n",
    "    description=(\n",
    "        \"Training feature view for water level prediction. \"\n",
    "        \"Combines lagged water level features, weather features, \"\n",
    "        \"and on-demand month one-hot encoding.\"\n",
    "    ),\n",
    "    labels=[\"water_level_cm\"],   # prediction target\n",
    "    transformation_functions=[add_month_one_hot],\n",
    ")"
   ],
   "id": "e287bab7c171a750",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 18:42:07,631 WARNING: UserWarning: Cannot extract imported dependencies for the UDF from the module in which it is defined. Please make sure to import all dependencies for the UDF inside the function.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fetch weather predictions",
   "id": "d4c089e76af3055f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:42:25.448274Z",
     "start_time": "2026-01-11T17:42:11.751166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = fv.training_data(\n",
    "    description=\"bla bla bla\"\n",
    ")\n",
    "print(X_train.columns)"
   ],
   "id": "1c0a85f528fc07e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.65s) from Hopsworks, using Hopsworks Feature Query Service.   Reading data from Hopsworks, using Hopsworks Feature Query Service...   \n",
      "2026-01-11 18:42:24,009 INFO: Computing insert statistics\n",
      "2026-01-11 18:42:25,442 WARNING: VersionWarning: Incremented version to `2`.\n",
      "\n",
      "Index(['date', 'water_level_cm_t_1', 'water_level_cm_t_3',\n",
      "       'water_level_cm_t_7', 'water_level_cm_t_14', 'precipitation_sum',\n",
      "       'snowfall_sum', 'rain_sum', 'temperature_2m_mean',\n",
      "       'wind_speed_10m_mean', 'surface_pressure_mean', 'precip_sum_3d',\n",
      "       'precip_sum_7d', 'precip_sum_14d', 'snow_sum_14d', 'snow_sum_30d',\n",
      "       'snow_sum_60d', 'precipitation_sum_n_75km', 'snowfall_sum_n_75km',\n",
      "       'rain_sum_n_75km', 'temperature_2m_mean_n_75km',\n",
      "       'wind_speed_10m_mean_n_75km', 'surface_pressure_mean_n_75km',\n",
      "       'precipitation_sum_s_75km', 'snowfall_sum_s_75km', 'rain_sum_s_75km',\n",
      "       'temperature_2m_mean_s_75km', 'wind_speed_10m_mean_s_75km',\n",
      "       'surface_pressure_mean_s_75km', 'precipitation_sum_e_75km',\n",
      "       'snowfall_sum_e_75km', 'rain_sum_e_75km', 'temperature_2m_mean_e_75km',\n",
      "       'wind_speed_10m_mean_e_75km', 'surface_pressure_mean_e_75km',\n",
      "       'precipitation_sum_w_75km', 'snowfall_sum_w_75km', 'rain_sum_w_75km',\n",
      "       'temperature_2m_mean_w_75km', 'wind_speed_10m_mean_w_75km',\n",
      "       'surface_pressure_mean_w_75km', 'add_month_one_hot_date_0',\n",
      "       'add_month_one_hot_date_1', 'add_month_one_hot_date_2',\n",
      "       'add_month_one_hot_date_3', 'add_month_one_hot_date_4',\n",
      "       'add_month_one_hot_date_5', 'add_month_one_hot_date_6',\n",
      "       'add_month_one_hot_date_7', 'add_month_one_hot_date_8',\n",
      "       'add_month_one_hot_date_9', 'add_month_one_hot_date_10',\n",
      "       'add_month_one_hot_date_11'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:42:25.469993Z",
     "start_time": "2026-01-11T17:42:25.456201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ensure datetime dtype\n",
    "X_train[\"date\"] = pd.to_datetime(X_train[\"date\"])\n",
    "\n",
    "# sort by time (ascending)\n",
    "X_train = X_train.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# do the same for y_train so rows still match X_train\n",
    "y_train = y_train.loc[X_train.index].reset_index(drop=True)\n",
    "\n",
    "# (optional) if y_train has its own date column or index, easiest is to merge instead\n",
    "print(X_train.tail())"
   ],
   "id": "124cdd35b0c13703",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  water_level_cm_t_1  water_level_cm_t_3  water_level_cm_t_7  \\\n",
      "2182 2026-01-05             29262.0             29263.0             29269.0   \n",
      "2183 2026-01-06             29263.0             29262.0             29265.0   \n",
      "2184 2026-01-07             29263.0             29262.0             29266.0   \n",
      "2185 2026-01-08             29262.0             29263.0             29266.0   \n",
      "2186 2026-01-09             29262.0             29263.0             29263.0   \n",
      "\n",
      "      water_level_cm_t_14  precipitation_sum  snowfall_sum  rain_sum  \\\n",
      "2182              29272.0                0.0          0.00       0.0   \n",
      "2183              29272.0                0.9          0.63       0.0   \n",
      "2184              29271.0                2.8          1.96       0.0   \n",
      "2185              29270.0                6.0          4.20       0.0   \n",
      "2186              29269.0                0.4          0.28       0.0   \n",
      "\n",
      "      temperature_2m_mean  wind_speed_10m_mean  ...  add_month_one_hot_date_2  \\\n",
      "2182                -21.8                  3.2  ...                         0   \n",
      "2183                -24.5                  4.4  ...                         0   \n",
      "2184                -11.7                 16.3  ...                         0   \n",
      "2185                 -7.1                 23.5  ...                         0   \n",
      "2186                 -7.1                 16.3  ...                         0   \n",
      "\n",
      "      add_month_one_hot_date_3  add_month_one_hot_date_4  \\\n",
      "2182                         0                         0   \n",
      "2183                         0                         0   \n",
      "2184                         0                         0   \n",
      "2185                         0                         0   \n",
      "2186                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_5  add_month_one_hot_date_6  \\\n",
      "2182                         0                         0   \n",
      "2183                         0                         0   \n",
      "2184                         0                         0   \n",
      "2185                         0                         0   \n",
      "2186                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_7  add_month_one_hot_date_8  \\\n",
      "2182                         0                         0   \n",
      "2183                         0                         0   \n",
      "2184                         0                         0   \n",
      "2185                         0                         0   \n",
      "2186                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_9  add_month_one_hot_date_10  \\\n",
      "2182                         0                          0   \n",
      "2183                         0                          0   \n",
      "2184                         0                          0   \n",
      "2185                         0                          0   \n",
      "2186                         0                          0   \n",
      "\n",
      "      add_month_one_hot_date_11  \n",
      "2182                          0  \n",
      "2183                          0  \n",
      "2184                          0  \n",
      "2185                          0  \n",
      "2186                          0  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get the weather feature group seperately",
   "id": "faf9a0eb9c0d348a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:22.279086Z",
     "start_time": "2026-01-11T17:42:25.512883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def get_or_create_feature_view_with_retry(*, retries: int = 1, sleep_s: float = 2.0, **kwargs):\n",
    "    \"\"\"\n",
    "    Call fs.get_or_create_feature_view(**kwargs) with a single retry on any exception.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    retries : int\n",
    "        Number of retries after the first failure (default: 1 -> total 2 attempts).\n",
    "    sleep_s : float\n",
    "        Seconds to sleep before retrying.\n",
    "    **kwargs\n",
    "        Passed directly to fs.get_or_create_feature_view.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FeatureView\n",
    "        The created or retrieved feature view.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    Exception\n",
    "        Re-raises the last exception if all attempts fail.\n",
    "    \"\"\"\n",
    "    last_exc = None\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            return fs.get_or_create_feature_view(**kwargs)\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            if attempt >= retries:\n",
    "                raise\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    # unreachable, but keeps type checkers happy\n",
    "    raise last_exc\n",
    "\n",
    "\n",
    "# 1) build the query for weather only\n",
    "weather_query = (\n",
    "    weather_fg\n",
    "    .select([\"sensor_id\", \"date\"] + weather_features)\n",
    "    # (optional) if you want only one sensor_id inside the view:\n",
    "    .filter(weather_fg.sensor_id == sensor_id)\n",
    ")\n",
    "\n",
    "# 2) create feature view\n",
    "weather_fv = get_or_create_feature_view_with_retry(\n",
    "    retries=1,\n",
    "    sleep_s=2.0,\n",
    "    name=f\"weather_view_{sensor_name}_{sensor_id}\",\n",
    "    version=1,\n",
    "    query=weather_query,\n",
    "    description=\"Weather-only feature view (includes spatial + aggregated weather features).\",\n",
    "    transformation_functions=[add_month_one_hot],\n",
    ")"
   ],
   "id": "97985732e008243b",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.010829Z",
     "start_time": "2026-01-11T17:43:22.294827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_weather = weather_fv.get_batch_data(data_format=\"pandas\")\n",
    "print(df_weather)"
   ],
   "id": "a6debdb389a11b8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.68s) from Hopsworks, using Hopsworks Feature Query Service.   \n",
      "      sensor_id       date  precipitation_sum  snowfall_sum  rain_sum  \\\n",
      "0         20048 2020-02-29                0.4          0.28       0.0   \n",
      "1         20048 2020-03-01                3.1          2.17       0.0   \n",
      "2         20048 2020-03-02               12.7          8.89       0.0   \n",
      "3         20048 2020-03-03                2.9          2.03       0.0   \n",
      "4         20048 2020-03-04                7.7          5.32       0.1   \n",
      "...         ...        ...                ...           ...       ...   \n",
      "2152      20048 2026-01-20                0.5          0.00       0.5   \n",
      "2153      20048 2026-01-21                0.1          0.00       0.1   \n",
      "2154      20048 2026-01-22                0.0          0.00       0.0   \n",
      "2155      20048 2026-01-23                0.0          0.00       0.0   \n",
      "2156      20048 2026-01-24                0.0          0.00       0.0   \n",
      "\n",
      "      temperature_2m_mean  wind_speed_10m_mean  surface_pressure_mean  \\\n",
      "0                    -6.5                  9.1                  960.3   \n",
      "1                    -9.2                 10.6                  953.1   \n",
      "2                    -7.6                 15.2                  959.4   \n",
      "3                    -6.2                 11.6                  976.0   \n",
      "4                    -4.5                 11.3                  973.6   \n",
      "...                   ...                  ...                    ...   \n",
      "2152                  1.2                 20.1                  969.2   \n",
      "2153                  1.8                 21.8                  972.4   \n",
      "2154                 -3.0                  6.3                  972.4   \n",
      "2155                 -7.6                  4.2                  974.0   \n",
      "2156                 -0.2                 18.7                  974.8   \n",
      "\n",
      "      precip_sum_3d  precip_sum_7d  ...  add_month_one_hot_date_2  \\\n",
      "0               0.4            1.1  ...                         0   \n",
      "1               3.5            3.5  ...                         1   \n",
      "2              16.2           16.2  ...                         1   \n",
      "3              18.7           19.1  ...                         1   \n",
      "4              23.3           26.8  ...                         1   \n",
      "...             ...            ...  ...                       ...   \n",
      "2152            4.1            6.9  ...                         0   \n",
      "2153            0.8            6.3  ...                         0   \n",
      "2154            0.6            6.3  ...                         0   \n",
      "2155            0.1            4.8  ...                         0   \n",
      "2156            0.0            4.2  ...                         0   \n",
      "\n",
      "      add_month_one_hot_date_3  add_month_one_hot_date_4  \\\n",
      "0                            0                         0   \n",
      "1                            0                         0   \n",
      "2                            0                         0   \n",
      "3                            0                         0   \n",
      "4                            0                         0   \n",
      "...                        ...                       ...   \n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_5  add_month_one_hot_date_6  \\\n",
      "0                            0                         0   \n",
      "1                            0                         0   \n",
      "2                            0                         0   \n",
      "3                            0                         0   \n",
      "4                            0                         0   \n",
      "...                        ...                       ...   \n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_7  add_month_one_hot_date_8  \\\n",
      "0                            0                         0   \n",
      "1                            0                         0   \n",
      "2                            0                         0   \n",
      "3                            0                         0   \n",
      "4                            0                         0   \n",
      "...                        ...                       ...   \n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_9  add_month_one_hot_date_10  \\\n",
      "0                            0                          0   \n",
      "1                            0                          0   \n",
      "2                            0                          0   \n",
      "3                            0                          0   \n",
      "4                            0                          0   \n",
      "...                        ...                        ...   \n",
      "2152                         0                          0   \n",
      "2153                         0                          0   \n",
      "2154                         0                          0   \n",
      "2155                         0                          0   \n",
      "2156                         0                          0   \n",
      "\n",
      "      add_month_one_hot_date_11  \n",
      "0                             0  \n",
      "1                             0  \n",
      "2                             0  \n",
      "3                             0  \n",
      "4                             0  \n",
      "...                         ...  \n",
      "2152                          0  \n",
      "2153                          0  \n",
      "2154                          0  \n",
      "2155                          0  \n",
      "2156                          0  \n",
      "\n",
      "[2157 rows x 50 columns]\n"
     ]
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.074720Z",
     "start_time": "2026-01-11T17:43:28.028085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])\n",
    "df_weather = df_weather.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "print(df_weather.head())\n",
    "print(df_weather.tail())"
   ],
   "id": "b1080adec10768a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensor_id       date  precipitation_sum  snowfall_sum  rain_sum  \\\n",
      "0      20048 2020-02-29                0.4          0.28       0.0   \n",
      "1      20048 2020-03-01                3.1          2.17       0.0   \n",
      "2      20048 2020-03-02               12.7          8.89       0.0   \n",
      "3      20048 2020-03-03                2.9          2.03       0.0   \n",
      "4      20048 2020-03-04                7.7          5.32       0.1   \n",
      "\n",
      "   temperature_2m_mean  wind_speed_10m_mean  surface_pressure_mean  \\\n",
      "0                 -6.5                  9.1                  960.3   \n",
      "1                 -9.2                 10.6                  953.1   \n",
      "2                 -7.6                 15.2                  959.4   \n",
      "3                 -6.2                 11.6                  976.0   \n",
      "4                 -4.5                 11.3                  973.6   \n",
      "\n",
      "   precip_sum_3d  precip_sum_7d  ...  add_month_one_hot_date_2  \\\n",
      "0            0.4            1.1  ...                         0   \n",
      "1            3.5            3.5  ...                         1   \n",
      "2           16.2           16.2  ...                         1   \n",
      "3           18.7           19.1  ...                         1   \n",
      "4           23.3           26.8  ...                         1   \n",
      "\n",
      "   add_month_one_hot_date_3  add_month_one_hot_date_4  \\\n",
      "0                         0                         0   \n",
      "1                         0                         0   \n",
      "2                         0                         0   \n",
      "3                         0                         0   \n",
      "4                         0                         0   \n",
      "\n",
      "   add_month_one_hot_date_5  add_month_one_hot_date_6  \\\n",
      "0                         0                         0   \n",
      "1                         0                         0   \n",
      "2                         0                         0   \n",
      "3                         0                         0   \n",
      "4                         0                         0   \n",
      "\n",
      "   add_month_one_hot_date_7  add_month_one_hot_date_8  \\\n",
      "0                         0                         0   \n",
      "1                         0                         0   \n",
      "2                         0                         0   \n",
      "3                         0                         0   \n",
      "4                         0                         0   \n",
      "\n",
      "   add_month_one_hot_date_9  add_month_one_hot_date_10  \\\n",
      "0                         0                          0   \n",
      "1                         0                          0   \n",
      "2                         0                          0   \n",
      "3                         0                          0   \n",
      "4                         0                          0   \n",
      "\n",
      "   add_month_one_hot_date_11  \n",
      "0                          0  \n",
      "1                          0  \n",
      "2                          0  \n",
      "3                          0  \n",
      "4                          0  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "      sensor_id       date  precipitation_sum  snowfall_sum  rain_sum  \\\n",
      "2152      20048 2026-01-20                0.5           0.0       0.5   \n",
      "2153      20048 2026-01-21                0.1           0.0       0.1   \n",
      "2154      20048 2026-01-22                0.0           0.0       0.0   \n",
      "2155      20048 2026-01-23                0.0           0.0       0.0   \n",
      "2156      20048 2026-01-24                0.0           0.0       0.0   \n",
      "\n",
      "      temperature_2m_mean  wind_speed_10m_mean  surface_pressure_mean  \\\n",
      "2152                  1.2                 20.1                  969.2   \n",
      "2153                  1.8                 21.8                  972.4   \n",
      "2154                 -3.0                  6.3                  972.4   \n",
      "2155                 -7.6                  4.2                  974.0   \n",
      "2156                 -0.2                 18.7                  974.8   \n",
      "\n",
      "      precip_sum_3d  precip_sum_7d  ...  add_month_one_hot_date_2  \\\n",
      "2152            4.1            6.9  ...                         0   \n",
      "2153            0.8            6.3  ...                         0   \n",
      "2154            0.6            6.3  ...                         0   \n",
      "2155            0.1            4.8  ...                         0   \n",
      "2156            0.0            4.2  ...                         0   \n",
      "\n",
      "      add_month_one_hot_date_3  add_month_one_hot_date_4  \\\n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_5  add_month_one_hot_date_6  \\\n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_7  add_month_one_hot_date_8  \\\n",
      "2152                         0                         0   \n",
      "2153                         0                         0   \n",
      "2154                         0                         0   \n",
      "2155                         0                         0   \n",
      "2156                         0                         0   \n",
      "\n",
      "      add_month_one_hot_date_9  add_month_one_hot_date_10  \\\n",
      "2152                         0                          0   \n",
      "2153                         0                          0   \n",
      "2154                         0                          0   \n",
      "2155                         0                          0   \n",
      "2156                         0                          0   \n",
      "\n",
      "      add_month_one_hot_date_11  \n",
      "2152                          0  \n",
      "2153                          0  \n",
      "2154                          0  \n",
      "2155                          0  \n",
      "2156                          0  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.138636Z",
     "start_time": "2026-01-11T17:43:28.087208Z"
    }
   },
   "cell_type": "code",
   "source": "print(df_weather.columns)",
   "id": "c2ef2a40f2398b0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sensor_id', 'date', 'precipitation_sum', 'snowfall_sum', 'rain_sum',\n",
      "       'temperature_2m_mean', 'wind_speed_10m_mean', 'surface_pressure_mean',\n",
      "       'precip_sum_3d', 'precip_sum_7d', 'precip_sum_14d', 'snow_sum_14d',\n",
      "       'snow_sum_30d', 'snow_sum_60d', 'precipitation_sum_n_75km',\n",
      "       'snowfall_sum_n_75km', 'rain_sum_n_75km', 'temperature_2m_mean_n_75km',\n",
      "       'wind_speed_10m_mean_n_75km', 'surface_pressure_mean_n_75km',\n",
      "       'precipitation_sum_s_75km', 'snowfall_sum_s_75km', 'rain_sum_s_75km',\n",
      "       'temperature_2m_mean_s_75km', 'wind_speed_10m_mean_s_75km',\n",
      "       'surface_pressure_mean_s_75km', 'precipitation_sum_e_75km',\n",
      "       'snowfall_sum_e_75km', 'rain_sum_e_75km', 'temperature_2m_mean_e_75km',\n",
      "       'wind_speed_10m_mean_e_75km', 'surface_pressure_mean_e_75km',\n",
      "       'precipitation_sum_w_75km', 'snowfall_sum_w_75km', 'rain_sum_w_75km',\n",
      "       'temperature_2m_mean_w_75km', 'wind_speed_10m_mean_w_75km',\n",
      "       'surface_pressure_mean_w_75km', 'add_month_one_hot_date_0',\n",
      "       'add_month_one_hot_date_1', 'add_month_one_hot_date_2',\n",
      "       'add_month_one_hot_date_3', 'add_month_one_hot_date_4',\n",
      "       'add_month_one_hot_date_5', 'add_month_one_hot_date_6',\n",
      "       'add_month_one_hot_date_7', 'add_month_one_hot_date_8',\n",
      "       'add_month_one_hot_date_9', 'add_month_one_hot_date_10',\n",
      "       'add_month_one_hot_date_11'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.165097Z",
     "start_time": "2026-01-11T17:43:28.157318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_required_feature_names(model) -> list[str]:\n",
    "    # Prefer booster feature names (best for XGBRegressor loaded from JSON)\n",
    "    booster = model.get_booster()\n",
    "    fn = booster.feature_names\n",
    "    if fn is None:\n",
    "        # fallback: scikit-style\n",
    "        if hasattr(model, \"feature_names_in_\"):\n",
    "            fn = list(model.feature_names_in_)\n",
    "        else:\n",
    "            raise ValueError(\"Model has no feature names. Train with pandas DataFrame so names are stored.\")\n",
    "    return list(fn)\n",
    "\n",
    "print(get_required_feature_names(retrieved_xgboost_model))"
   ],
   "id": "360a49ed9db02a5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water_level_cm_t_1', 'water_level_cm_t_3', 'water_level_cm_t_7', 'water_level_cm_t_14', 'precipitation_sum', 'snowfall_sum', 'rain_sum', 'temperature_2m_mean', 'wind_speed_10m_mean', 'surface_pressure_mean', 'precip_sum_3d', 'precip_sum_7d', 'precip_sum_14d', 'snow_sum_14d', 'snow_sum_30d', 'snow_sum_60d', 'precipitation_sum_n_75km', 'snowfall_sum_n_75km', 'rain_sum_n_75km', 'temperature_2m_mean_n_75km', 'wind_speed_10m_mean_n_75km', 'surface_pressure_mean_n_75km', 'precipitation_sum_s_75km', 'snowfall_sum_s_75km', 'rain_sum_s_75km', 'temperature_2m_mean_s_75km', 'wind_speed_10m_mean_s_75km', 'surface_pressure_mean_s_75km', 'precipitation_sum_e_75km', 'snowfall_sum_e_75km', 'rain_sum_e_75km', 'temperature_2m_mean_e_75km', 'wind_speed_10m_mean_e_75km', 'surface_pressure_mean_e_75km', 'precipitation_sum_w_75km', 'snowfall_sum_w_75km', 'rain_sum_w_75km', 'temperature_2m_mean_w_75km', 'wind_speed_10m_mean_w_75km', 'surface_pressure_mean_w_75km', 'add_month_one_hot_date_0', 'add_month_one_hot_date_1', 'add_month_one_hot_date_2', 'add_month_one_hot_date_3', 'add_month_one_hot_date_4', 'add_month_one_hot_date_5', 'add_month_one_hot_date_6', 'add_month_one_hot_date_7', 'add_month_one_hot_date_8', 'add_month_one_hot_date_9', 'add_month_one_hot_date_10', 'add_month_one_hot_date_11']\n"
     ]
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.234589Z",
     "start_time": "2026-01-11T17:43:28.213289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def predict_water_level_next_days(\n",
    "    model,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    df_weather_all: pd.DataFrame,\n",
    "    horizon_days: int = 14,\n",
    "    date_col: str = \"date\",\n",
    ") -> pd.DataFrame:\n",
    "    # --- Prepare history series (date -> water_level_cm actual) ---\n",
    "    Xh = X_train.copy()\n",
    "    Xh[date_col] = pd.to_datetime(Xh[date_col])\n",
    "\n",
    "    # y_train might be DataFrame (n,1); get the series\n",
    "    y_series = y_train.iloc[:, 0].copy()\n",
    "    hist = pd.DataFrame({date_col: Xh[date_col].values, \"water_level_cm\": y_series.values})\n",
    "    hist = hist.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "    # Use a dict for fast lookup of actual/pred values by date\n",
    "    wl_by_date = dict(zip(hist[date_col], hist[\"water_level_cm\"]))\n",
    "\n",
    "    last_date = hist[date_col].max()\n",
    "\n",
    "    # --- Prepare weather dataframe keyed by date ---\n",
    "    wf = df_weather_all.copy()\n",
    "    if date_col in wf.columns:\n",
    "        wf[date_col] = pd.to_datetime(wf[date_col])\n",
    "        wf = wf.set_index(date_col)\n",
    "    else:\n",
    "        # assume index is time-like\n",
    "        wf.index = pd.to_datetime(wf.index)\n",
    "\n",
    "    wf = wf.sort_index()\n",
    "\n",
    "    # --- Determine required feature columns in correct order ---\n",
    "    required = get_required_feature_names(model)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for step in range(1, horizon_days + 1):\n",
    "        d = last_date + timedelta(days=step)\n",
    "\n",
    "        # Weather features for that day\n",
    "        if d not in wf.index:\n",
    "            raise KeyError(f\"No weather features available for forecast date {d.date()} in df_weather_all.\")\n",
    "\n",
    "        row = wf.loc[d].to_dict()\n",
    "        # If wf.loc[d] returns a Series, dict is fine; if it returns multiple rows, error out\n",
    "        if isinstance(wf.loc[d], pd.DataFrame):\n",
    "            raise ValueError(f\"Multiple weather rows for date {d.date()}; ensure one row per day.\")\n",
    "\n",
    "        # --- Build lag features from wl_by_date (mix of actual & predicted) ---\n",
    "        def wl_at(date_):\n",
    "            if date_ not in wl_by_date:\n",
    "                raise KeyError(f\"Missing water level for {date_.date()} needed for lags of {d.date()}.\")\n",
    "            return float(wl_by_date[date_])\n",
    "\n",
    "        row[\"water_level_cm_t_1\"]  = wl_at(d - timedelta(days=1))\n",
    "        row[\"water_level_cm_t_3\"]  = wl_at(d - timedelta(days=3))\n",
    "        row[\"water_level_cm_t_7\"]  = wl_at(d - timedelta(days=7))\n",
    "        row[\"water_level_cm_t_14\"] = wl_at(d - timedelta(days=14))\n",
    "\n",
    "        # If your model includes the date column or month-one-hot columns, handle them:\n",
    "        # - If \"date\" is part of required features, set it\n",
    "        if date_col in required:\n",
    "            row[date_col] = d\n",
    "\n",
    "        # --- Create one-row DF with EXACT required columns (missing -> 0) ---\n",
    "        X_row = pd.DataFrame([{col: row.get(col, 0) for col in required}], columns=required)\n",
    "\n",
    "        # Make sure numeric columns are numeric\n",
    "        for c in X_row.columns:\n",
    "            if c != date_col:\n",
    "                X_row[c] = pd.to_numeric(X_row[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "        y_pred = float(model.predict(X_row)[0])\n",
    "\n",
    "        # store prediction\n",
    "        preds.append({date_col: d, \"water_level_cm_pred\": y_pred})\n",
    "\n",
    "        # feed prediction back for future lags\n",
    "        wl_by_date[d] = y_pred\n",
    "\n",
    "    return pd.DataFrame(preds).sort_values(date_col).reset_index(drop=True)\n"
   ],
   "id": "283b31f5f1e664c",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.516733Z",
     "start_time": "2026-01-11T17:43:28.276342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_weather_all should contain rows for the forecast horizon dates (daily)\n",
    "# and columns matching what the model was trained on (weather_features etc.)\n",
    "pred_df = predict_water_level_next_days(\n",
    "    retrieved_xgboost_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    df_weather_all=df_weather,   # <- your forecast features dataframe\n",
    "    horizon_days=14,\n",
    "    date_col=\"date\",\n",
    ")\n",
    "\n",
    "print(pred_df)"
   ],
   "id": "8fd17488196c98f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  water_level_cm_pred\n",
      "0  2026-01-10         29247.287109\n",
      "1  2026-01-11         29245.765625\n",
      "2  2026-01-12         29243.691406\n",
      "3  2026-01-13         29241.992188\n",
      "4  2026-01-14         29239.458984\n",
      "5  2026-01-15         29237.306641\n",
      "6  2026-01-16         29234.662109\n",
      "7  2026-01-17         29231.939453\n",
      "8  2026-01-18         29229.109375\n",
      "9  2026-01-19         29226.841797\n",
      "10 2026-01-20         29225.335938\n",
      "11 2026-01-21         29221.562500\n",
      "12 2026-01-22         29219.441406\n",
      "13 2026-01-23         29217.457031\n"
     ]
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:43:28.535906Z",
     "start_time": "2026-01-11T17:43:28.528656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "HERE = Path(__file__).resolve().parent          # notebooks/\n",
    "REPO_ROOT = HERE.parent                         # repo root (assuming scripts/ is in repo root)\n",
    "\n",
    "ARTIFACTS_DIR = REPO_ROOT / \"artifacts\"\n",
    "PREDICTIONS_DIR = ARTIFACTS_DIR / \"predictions\"\n",
    "prediction_file = f\"predictions_{sensor_name}_{sensor_id}.csv\"\n",
    "\n",
    "prediction_path = PREDICTIONS_DIR / prediction_file\n",
    "\n",
    "pred_df.to_csv(prediction_path, index=False)\n",
    "print(f\"Saved predictions to: {prediction_path}\")"
   ],
   "id": "988298de2f8fcb71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to: ../artifacts/predictions/predictions_storsjon_jamtland_20048.csv\n"
     ]
    }
   ],
   "execution_count": 231
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
